{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/IIT-Summer-2023/blob/main/SA2023_W4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wif8v0Oj06dc"
      },
      "source": [
        "# SUMMER ANALYTICS 2023\n",
        "\n",
        "## WEEK-4 ASSIGNMENT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # data visualization\n",
        "import seaborn as sns # statistical data visualization\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "iE-YDRYYRPh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's explore the dataset shall we?**"
      ],
      "metadata": {
        "id": "0RNgIwiONc5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[The Car Evaluation Database](https://drive.google.com/file/d/1ck5JUuRP0MY_k1hFwqx5Uc8iQJwqHkYJ/view?usp=sharing) contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maintenance cost, doors, persons, lug_boot, safety.\n",
        "In this notebook we will go through an in depth analysis of sound and how we can classify and ultimately understand it.\n",
        "\n",
        "I suggest you to use the internet before asking a doubt. Most of your doubts will disappear once you read the documentation or search StackOverflow!\n",
        "\n",
        "Note: Pay close attention to the markdown cells and the comments."
      ],
      "metadata": {
        "id": "vSbvNVTdNj3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file as data\n",
        "\n",
        "# you may print first few rows\n",
        "# data.head()\n"
      ],
      "metadata": {
        "id": "g8GUshlWRdsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attribute Information->\n",
        "\n",
        "Class Values: unacc, acc, good, vgood\n",
        "\n",
        "Attributes->\n",
        "buying- vhigh, high, med, low.\n",
        "maint- vhigh, high, med, low.\n",
        "doors -2, 3, 4, 5more.\n",
        "persons-2, 4, more.\n",
        "lug_boot- small, med, big.\n",
        "safety- low, med, high."
      ],
      "metadata": {
        "id": "wmkJps7-SgDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "JwPs1FWHRvp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view dimensions of dataset\n",
        "df.shape"
      ],
      "metadata": {
        "id": "jC94tNRNUmEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are 1727 instances and 7 variables in the data set.\n",
        "\n"
      ],
      "metadata": {
        "id": "1JEV4_b7R3xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rename column names**\n",
        "We can see that the dataset does not have proper column names. The columns are merely labelled as 0,1,2.... and so on. We should give proper names to the columns. I will do it as follows:-"
      ],
      "metadata": {
        "id": "s02qpTMLWJoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "df.columns = col_names\n",
        "col_names"
      ],
      "metadata": {
        "id": "XrBfGqhkUm63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency distribution of values in variables\n",
        "Now, I will check the frequency counts of categorical variable"
      ],
      "metadata": {
        "id": "DszF0azswSJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "for col in col_names:\n",
        "    print(df[col].value_counts())"
      ],
      "metadata": {
        "id": "Yi0hwKOuUuB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the doors and persons are categorical in nature. So, I will treat them as categorical variables.\n",
        "\n",
        "Summary of variables\n",
        "There are 7 variables in the dataset. All the variables are of categorical data type.\n",
        "These are given by buying, maint, doors, persons, lug_boot, safety and class.\n",
        "class is the target variable."
      ],
      "metadata": {
        "id": "DFsMxqQy0Ux_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values in variables\n",
        "#write your code here\n"
      ],
      "metadata": {
        "id": "kanxuW8QVI3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Declare feature vector and target variable**"
      ],
      "metadata": {
        "id": "XEd63OSL0ivl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['class'], axis=1)\n",
        "\n",
        "y = df['class']"
      ],
      "metadata": {
        "id": "bTnqqBl3VNQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data into separate training and test set**"
      ],
      "metadata": {
        "id": "ofmJ_Aia0qnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  split X and y into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
      ],
      "metadata": {
        "id": "PIh4mN0qVYXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape of X_train and X_test\n"
      ],
      "metadata": {
        "id": "zgVwzExIVdMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "AknjxL5Z6UVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. I will carry out feature engineering on different types of variables."
      ],
      "metadata": {
        "id": "Nb7ENGw66Y32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check data types in X_train\n",
        "\n"
      ],
      "metadata": {
        "id": "-6XRHPIvVomY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode categorical variables\n",
        "Now, I will encode the categorical variables."
      ],
      "metadata": {
        "id": "rrmnX8Re6cdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "pzq5NJGKVyWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that all the variables are ordinal categorical data type.\n",
        "\n"
      ],
      "metadata": {
        "id": "aFiLBe146hwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.apply(LabelEncoder().fit_transform)\n",
        "X_test = X_test.apply(LabelEncoder().fit_transform)"
      ],
      "metadata": {
        "id": "nBIlFaUmV5z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()\n"
      ],
      "metadata": {
        "id": "1hLAHKhMWDg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's perform Machine Learning Classification. We'll be predicting the genre based on the given features."
      ],
      "metadata": {
        "id": "qNB7jyd_Emd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "from xgboost import plot_tree, plot_importance\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_selection import RFE"
      ],
      "metadata": {
        "id": "aHSwTu9fWDmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Predefined function to assess the accuracy of a model. This will be the scoring function"
      ],
      "metadata": {
        "id": "CPgdqiQgE9Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score(model, title = \"Default\"):\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "#     print(confusion_matrix(y_test, preds))\n",
        "    accuracy = round(accuracy_score(y_test, preds), 5)\n",
        "    print('Accuracy for', title, ':', accuracy, '\\n')"
      ],
      "metadata": {
        "id": "4aqlvpu3WPeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Let's see how a basic Logistic Regressor works on this!"
      ],
      "metadata": {
        "id": "jP-kKojZFDJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
        "score(lg, \"Logistic Regression\")"
      ],
      "metadata": {
        "id": "TJibjWO1WT9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now it's your turn. Train the following:**"
      ],
      "metadata": {
        "id": "18wwH-F0FT3w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxNHTPTQM8R6"
      },
      "source": [
        "4. **AdaBoostClassifier** with n_estimators=1000 & random_state=0\n",
        "5. **RandomForestClassifier** with n_estimators=1000, max_depth=10, random_state=0\n",
        "\n",
        "**IMPORTANT**: Use the default values for other hyper parameters apart from these. Do **NOT** change these values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoostClassifier\n",
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ZPurc-gqWhb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "uSYvfL6tWhz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost performs poorly, but Random Forest looks great!\n",
        "\n",
        "Now look at the import statements. There may be a few models you may or may not have seen. Use those models to beat the score you achieved in the cell above! Play around with their hyper parameters.\n",
        "We suggest going through their documentations before using them."
      ],
      "metadata": {
        "id": "paLxFePkFogB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes: GaussianNB\n",
        "#YOUR CODE HERE\n",
        "\n",
        "# KNN: KNeighborsClassifier\n",
        "#YOUR CODE HERE\n",
        "\n",
        "# Decission trees: DecisionTreeClassifier\n",
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "q86kHRSCWquQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize decision-trees"
      ],
      "metadata": {
        "id": "TI58ewjYeaDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(200,30))\n",
        "\n",
        "from sklearn import tree\n",
        "#change the model name\n",
        "tree.plot_tree(\"model_name\")"
      ],
      "metadata": {
        "id": "QtcwZ4RFefQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier with criterion gini index,max_depth=10, random_state=0"
      ],
      "metadata": {
        "id": "av19xchZk5dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "wBsOf-krl07B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier with criterion entripy index,max_depth=8, random_state=0"
      ],
      "metadata": {
        "id": "KDReCw1alZse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Rx7dwV1Ql4ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use XGBClassifier with n_estimators=1000 and learning_rate=0.01"
      ],
      "metadata": {
        "id": "sM9dA_21F4qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBClassifier\n",
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "VjIIyGzWYLg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize XGBClassifier"
      ],
      "metadata": {
        "id": "Iis0T8gad4k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_tree\n",
        "fig, ax = plt.subplots(figsize=(30, 30))\n",
        "#change the model name\n",
        "plot_tree(\"model_name\", ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KvjnVgh8d8XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, heres a task for you. Try XGBRFClassifier on your own."
      ],
      "metadata": {
        "id": "Hjuv0EU-GCAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBRFClassifier"
      ],
      "metadata": {
        "id": "hyXIbHx4bTey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Confusion Matrix for XGBClassifier with parameters n_estimators=1000, learning_rate=0.1"
      ],
      "metadata": {
        "id": "J88ePcaGGMUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to plot Confusion Matrix\n",
        "#YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "g3TPJqt4bkuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQod3Rqx06ds"
      },
      "source": [
        "8. Find the feature importance for XGBClassifier.\n",
        "\n",
        "*Hint: It's an inbuilt member variable*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to find Feature Importance\n",
        "#YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "2OCY65PHbp0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Report**\n",
        "Classification report is another way to evaluate the classification model performance. It displays the precision, recall, f1 and support scores for the model. I have described these terms in later.\n",
        "\n",
        "We can print a classification for XGBClassifierwith parameters n_estimators=1000, learning_rate=0.1"
      ],
      "metadata": {
        "id": "1wFLUjzyKvej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "_I1lBQzYb888"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}